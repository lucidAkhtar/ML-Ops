diff --git a/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/upload_artifact.py b/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/upload_artifact.py
index cb43d39..7cca082 100644
--- a/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/upload_artifact.py
+++ b/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/upload_artifact.py
@@ -17,6 +17,9 @@ def go(args):
 
     # YOUR CODE HERE
 
+    run = wandb.init(project='practice_pipelines',group='artifact_creation',job_type='upload_file')
+
+
     # Create an instance of the class ``wandb.Artifact``. Use the ``artifact_name`` parameter to fill
     # the keyword ``name`` when constructing the wandb.Artifact class.
     # Use the parameters ``artifact_type`` and ``artifact_desc`` to fill respectively the keyword
@@ -25,15 +28,25 @@ def go(args):
 
     # YOUR CODE HERE
 
+    artifact = wandb.Artifact(
+        name = args.artifact_name,
+        type = args.artifact_type,
+        description = args.artifact_description
+    )
+
     # Attach the file provided as the parameter ``input_file`` to the artifact instance using
     # ``artifact.add_file``, and log the artifact to the run using ``run.log_artifact``.
 
     # YOUR CODE HERE
 
+    artifact.add_file(args.input_file)
+    run.log_artifact(artifact)
+
 
 if __name__ == "__main__":
     parser = argparse.ArgumentParser(
-        description="Upload an artifact to W&B", fromfile_prefix_chars="@"
+        description="Upload an artifact to W&B"
+        #fromfile_prefix_chars="@"
     )
 
     parser.add_argument(
diff --git a/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/use_artifact.py b/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/use_artifact.py
index f455e13..5c5c083 100644
--- a/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/use_artifact.py
+++ b/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/use_artifact.py
@@ -11,14 +11,16 @@ logger = logging.getLogger()
 
 def go(args):
 
-    logger.info("Creating run in project exercise_1")
-    run = wandb.init(project="exercise_1", job_type="use_file")
+    logger.info("Creating run in project practice_pipelines")
+    run = wandb.init(project="practice_pipelines", job_type="use_file")
 
     logger.info("Getting artifact")
 
     # YOUR CODE HERE: get the artifact and store its local path in the variable "artifact_path"
     # HINT: you can get the artifact path by using the "file()" method
 
+    artifact = run.use_artifact(args.artifact_name)
+
     artifact_path = artifact.file()
 
     logger.info("Artifact content:")
diff --git a/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/zen.txt b/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/zen.txt
index 634c12b..4118783 100644
--- a/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/zen.txt
+++ b/lesson-1-machine-learning-pipelines/exercises/exercise_1/starter/zen.txt
@@ -19,3 +19,4 @@ Although never is often better than *right* now.
 If the implementation is hard to explain, it's a bad idea.
 If the implementation is easy to explain, it may be a good idea.
 Namespaces are one honking great idea -- let's do more of those!
+This is a demo created by Specialist Akhtar
\ No newline at end of file
diff --git a/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/conda.yml b/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/conda.yml
index b735436..3c390f0 100644
--- a/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/conda.yml
+++ b/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/conda.yml
@@ -3,4 +3,9 @@ channels:
   - conda-forge
   - defaults
 dependencies:
-  # Complete HERE
+  - requests=2.24.0
+  - pip=20.3.3
+  - mlflow=1.14.1
+  - hydra-core=1.1.1
+  - pip:
+      - wandb==0.12.4
diff --git a/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/main.py b/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/main.py
index 47fba9e..626b4b5 100644
--- a/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/main.py
+++ b/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/main.py
@@ -1,7 +1,11 @@
 import mlflow
 import os
 import hydra
+from mlflow.utils import uri 
+# package for Facebook research for configuring complex applications
+# pip install hydra-core --upgrade
 from omegaconf import DictConfig
+# pip install --upgrade omegaconf
 
 
 # This automatically reads in the configuration
@@ -16,14 +20,16 @@ def go(config: DictConfig):
     root_path = hydra.utils.get_original_cwd()
 
     _ = mlflow.run(
-        os.path.join(root_path, "download_data"),
-        "main",
+        # URI can be a local path or the URL to a git repository
+        # here we are going to use a local path
+        uri = os.path.join(root_path, "download_data"),
+        entry_point = "main",
         parameters={
             "file_url": config["data"]["file_url"],
             "artifact_name": "iris.csv",
             "artifact_type": "raw_data",
             "artifact_description": "Input data"
-        },
+        }
     )
 
     ##################
@@ -33,7 +39,18 @@ def go(config: DictConfig):
     # to the "process_data" component
     ##################
 
-
+    _ = mlflow.run(
+        # URI can be a local path or the URL to a git repository
+        # here we are going to use a local path
+        uri = os.path.join(root_path, "process_data"),
+        entry_point = "main",
+        parameters={
+            "input_artifact": "iris.csv:latest",
+            "artifact_name": "clean_data.csv",
+            "artifact_type": "processed_data",
+            "artifact_description": "Clean data"
+        }
+    )
 
 if __name__ == "__main__":
     go()
diff --git a/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/process_data/run.py b/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/process_data/run.py
index c7ad9da..61645ab 100644
--- a/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/process_data/run.py
+++ b/lesson-1-machine-learning-pipelines/exercises/exercise_3/starter/process_data/run.py
@@ -1,4 +1,13 @@
 #!/usr/bin/env python
+
+# This particular task(here,processing.py) is done by using Command line arguments
+# The data path from a URL or a storage is considered and then the artifact is 
+# created. 
+# Artifact is considered as the Input and Output happening in ML mode building.
+# Then, making some changes in the data and applying T-SNE and saving the artifact
+# as the output of T-SNE TO W&B.
+# adding this artifact name, type and description taking this from the Command line
+# 
 import argparse
 import logging
 import seaborn as sns
@@ -13,6 +22,8 @@ logger = logging.getLogger()
 
 def go(args):
 
+    # Important step 
+    # Runs -> Group/Experiment -> Project (Weights & Biases)
     run = wandb.init(job_type="process_data")
 
     logger.info("Downloading artifact")
@@ -43,6 +54,7 @@ def go(args):
     logger.info("Creating artifact")
 
     iris.to_csv("clean_data.csv")
+    # Where is the data saved here
 
     artifact = wandb.Artifact(
         name=args.artifact_name,
diff --git a/lesson-2-data-exploration-and-preparation/exercises/exercise_4/starter/MLproject b/lesson-2-data-exploration-and-preparation/exercises/exercise_4/starter/MLproject
index e69de29..d287e19 100644
--- a/lesson-2-data-exploration-and-preparation/exercises/exercise_4/starter/MLproject
+++ b/lesson-2-data-exploration-and-preparation/exercises/exercise_4/starter/MLproject
@@ -0,0 +1,10 @@
+name: data_eda
+conda_env: conda.yml
+
+entry_points:
+  main:
+
+
+
+    command: >- 
+      jupyter notebook
\ No newline at end of file
diff --git a/lesson-2-data-exploration-and-preparation/exercises/exercise_4/starter/conda.yml b/lesson-2-data-exploration-and-preparation/exercises/exercise_4/starter/conda.yml
index f216511..9009a58 100644
--- a/lesson-2-data-exploration-and-preparation/exercises/exercise_4/starter/conda.yml
+++ b/lesson-2-data-exploration-and-preparation/exercises/exercise_4/starter/conda.yml
@@ -10,4 +10,4 @@ dependencies:
   - pandas-profiling=2.11.0
   - pyarrow=2.0
   - pip:
-      - wandb==0.10.21
\ No newline at end of file
+      - wandb==0.12.1
\ No newline at end of file
