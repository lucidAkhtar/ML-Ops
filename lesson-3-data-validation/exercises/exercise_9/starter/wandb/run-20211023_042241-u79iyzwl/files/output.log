[1m========================================== test session starts ===========================================
platform darwin -- Python 3.9.7, pytest-6.2.2, py-1.10.0, pluggy-0.13.1 -- /Users/pluto7/opt/miniconda3/envs/mlflow-0f4605a7f82725b3f21c1b32e06b5b072ad2a93b/bin/python
cachedir: .pytest_cache
rootdir: /Users/pluto7/Documents/mlops/nd0821-c2-build-model-workflow-exercises/lesson-3-data-validation/exercises/exercise_9/starter
[1mcollected 1 item                                                                                         
test_data.py::test_kolmogorov_smirnov [31mFAILED
================================================ FAILURES ================================================
[31m[1m________________________________________ test_kolmogorov_smirnov _________________________________________
data = (       Unnamed: 0  ...                                       text_feature
0           27919  ...                     ...ll on to Forrest Trance
12592       34043  ...                            Lost Lands 2019
[12593 rows x 19 columns])
ks_alpha = 0.9
    def test_kolmogorov_smirnov(data,ks_alpha):
        sample1, sample2 = data
        columns = [
            "danceability",
            "energy",
            "loudness",
            "speechiness",
            "acousticness",
            "instrumentalness",
            "liveness",
            "valence",
            "tempo",
            "duration_ms"
        ]
        # Bonferroni correction for multiple hypothesis testing
        # (see my blog post on this topic to see where this comes from:
        # https://towardsdatascience.com/precision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b)
        alpha_prime = 1 - (1 - ks_alpha)**(1 / len(columns))
        for col in columns:
            ts, p_value = scipy.stats.ks_2samp(sample1[col], sample2[col],
                                                alternative='two-sided')
            # NOTE: as always, the p-value should be interpreted as the probability of
            # obtaining a test statistic (TS) equal or more extreme that the one we got
            # by chance, when the null hypothesis is true. If this probability is not
            # large enough, this dataset should be looked at carefully, hence we fail
>           assert p_value > alpha_prime,("Null hypothesis rejected")
[31m[1mE           AssertionError: Null hypothesis rejected
[31m[1mE           assert 0.1910608811990394 > 0.2056717652757185
[31m[1mtest_data.py[39m[22m:37: AssertionError
======================================== short test summary info =========================================
FAILED test_data.py::test_kolmogorov_smirnov - AssertionError: Null hypothesis rejected
[31m=========================================== [1m1 failed[22m in 6.20s ============================================